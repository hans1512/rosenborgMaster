{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a1f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from boxmot import DeepOCSORT\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4517ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_tracker(model_weights, device='cuda:0', fp16=True):\n",
    "    \"\"\"\n",
    "    Initialize the DeepOCSORT tracker with the given model weights and device.\n",
    "    \"\"\"\n",
    "    tracker = DeepOCSORT(\n",
    "        model_weights=model_weights,\n",
    "        device=device,\n",
    "        fp16=fp16\n",
    "    )\n",
    "    return tracker\n",
    "\n",
    "def initialize_yolo(model_path):\n",
    "    \"\"\"\n",
    "    Initialize the YOLO object detector with the given model path.\n",
    "    \"\"\"\n",
    "    yolov8 = YOLO(model_path)\n",
    "    return yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e7df4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rect:\n",
    "    def __init__(self, x1, y1, x2, y2):\n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "        self.x2 = x2\n",
    "        self.y2 = y2\n",
    "    \n",
    "    @property\n",
    "    def bottom_center(self):\n",
    "        return ((self.x1 + self.x2) // 2, self.y2)\n",
    "    \n",
    "    @property\n",
    "    def width(self):\n",
    "        return self.x2 - self.x1\n",
    "\n",
    "class Color:\n",
    "    def __init__(self, b, g, r):\n",
    "        self.b = b\n",
    "        self.g = g\n",
    "        self.r = r\n",
    "\n",
    "    @property\n",
    "    def bgr_tuple(self):\n",
    "        return (self.b, self.g, self.r)\n",
    "\n",
    "def draw_ellipse(image, rect, color, thickness=2):\n",
    "    center = rect.bottom_center\n",
    "    axes = (int(rect.width), int(0.35 * rect.width))\n",
    "    cv2.ellipse(\n",
    "        image,\n",
    "        center,\n",
    "        axes,\n",
    "        angle=0.0,\n",
    "        startAngle=-45,\n",
    "        endAngle=235,\n",
    "        color=color.bgr_tuple,\n",
    "        thickness=thickness,\n",
    "        lineType=cv2.LINE_4\n",
    "    )\n",
    "    return image\n",
    "\n",
    "def lab_to_rgb(lab_color):\n",
    "    \"\"\"\n",
    "    Converts a single LAB color to RGB.\n",
    "    \"\"\"\n",
    "    lab_image = np.array([[lab_color]], dtype=np.uint8)\n",
    "    rgb_image = cv2.cvtColor(lab_image, cv2.COLOR_Lab2RGB)\n",
    "    return rgb_image[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc54bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_file, output_file, tracker, yolov8, conf=0.3):\n",
    "    \"\"\"\n",
    "    Process the input video, perform object detection and tracking, and save the results to the output video.\n",
    "    \"\"\"\n",
    "    input_video = cv2.VideoCapture(input_file)\n",
    "    width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = input_video.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_file, fourcc, fps, (width, height))\n",
    "    \n",
    "    thickness = 2\n",
    "    fontscale = 0.5\n",
    "    \n",
    "    # Function to get unique colors for each class id\n",
    "    def get_color(cls_id):\n",
    "        np.random.seed(cls_id)\n",
    "        return tuple(np.random.randint(0, 255, 3).tolist())\n",
    "    \n",
    "   \n",
    "\n",
    "    initial_centroids = None\n",
    "    counter = 1\n",
    "    while True:\n",
    "        print(counter)\n",
    "        ret, im = input_video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        predicted = yolov8.predict(im, conf=conf)\n",
    "        dets = predicted[0].boxes.data.cpu().numpy()\n",
    "        \"\"\"\n",
    "        tracks = tracker.update(dets, im)\n",
    "        if tracks.size > 0:  # Check if tracks is not empty\n",
    "            print(\"Tracks shape:\", tracks.shape)  # Print the shape of tracks\n",
    "            xyxys = tracks[:, 0:4].astype('int')\n",
    "            ids = tracks[:, 4].astype('int')\n",
    "            clss = tracks[:, 6].astype('int')\n",
    "        else:\n",
    "            print(\"Tracks is empty or not in expected format.\")\n",
    "        \n",
    "        #if(counter == 1):\n",
    "        #   compute_jersey_colors(im, dets, xyxys, clss)\n",
    "        \n",
    "        if tracks.shape[0] != 0:\n",
    "            #player_mean_colors = [get_mean_color(im, xyxy)[1] for xyxy, cls in zip(xyxys, clss) if cls == 1]\n",
    "            #player_mean_colors = [get_color_histogram(im, xyxy) for xyxy, cls in zip(xyxys, clss) if cls == 1]\n",
    "            \n",
    "            #if len(player_mean_colors) > 1:\n",
    "            #    labels, initial_centroids = perform_kmeans_clustering(player_mean_colors, initial_centroids)\n",
    "                \n",
    "                \n",
    "                player_mean_colors = np.array([lab_to_rgb(color) for color in player_mean_colors])\n",
    "                \n",
    "                # Plotting the results (optional)\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.scatter(player_mean_colors[:, 1], player_mean_colors[:, 2], c=player_mean_colors / 255.0)\n",
    "                plt.title('Original Colors')\n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.scatter(player_mean_colors[labels == 0][:, 1], player_mean_colors[labels == 0][:, 2], c='blue', marker='o')\n",
    "                plt.scatter(player_mean_colors[labels == 1][:, 1], player_mean_colors[labels == 1][:, 2], c='red', marker='x')\n",
    "                plt.title('Clustered Colors')\n",
    "\n",
    "                plt.show()\n",
    "                \n",
    "            \"\"\"\n",
    "            for xyxy, id, cls, label in zip(xyxys, ids, clss, labels):\n",
    "                \n",
    "                if cls == 1:  # Modify this condition as per your actual player class ID\n",
    "                    # Adjusting the bounding box to focus on the upper part\n",
    "                    x1, y1, x2, y2 = xyxy\n",
    "                    height = y2 - y1\n",
    "                    width = x2 - x1\n",
    "\n",
    "                    new_y1 = y1 + int(0.17 * height)\n",
    "                    new_y2 = y1 + int(0.5 * height)\n",
    "                    new_x1 = x1 + int(0.2 * width)\n",
    "                    new_x2 = x2 - int(0.2 * width)\n",
    "\n",
    "                    # Visualize the adjusted bounding box\n",
    "                    cv2.rectangle(im, (new_x1, new_y1), (new_x2, new_y2), (255, 0, 0), 2)\n",
    "                \n",
    "                \n",
    "                # Convert bounding box coordinates to Rect object\n",
    "                rect = Rect(xyxy[0], xyxy[1], xyxy[2], xyxy[3])\n",
    "                \n",
    "                if cls == 1:\n",
    "                    cls = cls + label\n",
    "                \n",
    "                # Get a unique color for each class\n",
    "                color = Color(*get_color(cls))\n",
    "\n",
    "                # Draw an ellipse at the bottom of the bounding box\n",
    "                draw_ellipse(im, rect, color, thickness)\n",
    "                \n",
    "                # Place ID text just above the ellipse\n",
    "                cv2.putText(\n",
    "                    im,\n",
    "                    f'{id}',\n",
    "                    (rect.bottom_center[0] - 10, rect.bottom_center[1] - int(0.35 * rect.width) - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontscale,\n",
    "                    color.bgr_tuple,\n",
    "                    thickness\n",
    "                )\n",
    "                \n",
    "                \n",
    "        out.write(im)\n",
    "        counter += 1\n",
    "        \n",
    "    input_video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6b30770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videos/2sec_tracking1_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-10-16 12:53:22.145\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m207\u001b[0m - \u001b[32m\u001b[1mSuccessfully loaded pretrained weights from \"osnet_x0_25_msmt17.pt\"\u001b[0m\n",
      "\u001b[32m2023-10-16 12:53:22.146\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m211\u001b[0m - \u001b[33m\u001b[1mThe following layers are discarded due to unmatched keys or layer size: ('classifier.weight', 'classifier.bias')\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1120x1984 1 ball, 22 players, 77.6ms\n",
      "Speed: 316.4ms preprocess, 77.6ms inference, 382.0ms postprocess per image at shape (1, 3, 1120, 1984)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks shape: (23, 8)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compute_jersey_colors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m tracker \u001b[38;5;241m=\u001b[39m initialize_tracker(model_weights)\n\u001b[1;32m     11\u001b[0m yolov8 \u001b[38;5;241m=\u001b[39m initialize_yolo(yolo_model_path)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_video_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_video_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myolov8\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mprocess_video\u001b[0;34m(input_file, output_file, tracker, yolov8, conf)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTracks is empty or not in expected format.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(counter \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mcompute_jersey_colors\u001b[49m(im, dets, xyxys, clss)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     45\u001b[0m     player_mean_colors \u001b[38;5;241m=\u001b[39m [get_mean_color(im, xyxy)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m xyxy, \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(xyxys, clss) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_jersey_colors' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_weights = Path('osnet_x0_25_msmt17.pt')\n",
    "yolo_model_path = 'runs/detect/NewDataset5008/weights/best.pt'\n",
    "input_video_file = \"videos/2sec.mp4\"\n",
    "print(input_video_file.split(\".\")[0] + \"_tracking1_output.mp4\")\n",
    "output_video_file = input_video_file.split(\".\")[0] + \"_tracking1_output.mp4\"\n",
    "\n",
    "tracker = initialize_tracker(model_weights)\n",
    "yolov8 = initialize_yolo(yolo_model_path)\n",
    "process_video(input_video_file, output_video_file, tracker, yolov8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178dd26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
